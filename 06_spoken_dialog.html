<html lang="ja">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Style-Type" content="text/css">
<meta http-equiv="Content-Script-Type" content="text/javascript">
<title>Spoken Dialog by Javascript</title>
<link rel="stylesheet" type="text/css" href="style.css"> <!-- cssを作成して適用しました。-->
</head>
<body>

<h1>美味しいラーメン屋さんの検索</h1>

<table> <!-- ボタンを横並びに表示させました。 -->
<tr>
<td><button id="startButton">start</button></td>
<td><button id="stopButton">stop</button></td>
<tr>
</table>

<p>
<div id="resultOutput"></div>
</p>

<script>
// 応答の定義（ハッシュ）
let response = { //キーワードで返答ができるようにしました。
		"こんにちは":"こんにちは、こちらは関西の美味しいラーメン屋さんを検索するサイトです",
		"おはよう":"おはようございます、こちらは関西の美味しいラーメン屋さんを検索するサイトです",
		"こんばんは":"こんばんは、こちらは関西の美味しいラーメン屋さんを検索するサイトです",
		"あなた,誰":"わたしは、めんじろうと申します",
		"何歳":"え、わたし、何歳にみえますか",
		"元気":"元気ですよー",
		"好き,食べ物":"ラーメンです",
		"どこ,出身":"東京です",
		"誕生日":"7月11日です",
		"好き,スポーツ":"野球です",
		"夢は":"全国のラーメン屋さんを制覇することです",
		"好き,色":"です",
		"好き,ラーメン":"豚骨です",
		"好き,ラーメン屋":"選べません",
		"おすすめ,ラーメン屋":"選べません"
};
let ramen = {
    "和歌山,ラーメン": ["和歌山県のラーメン屋さんを表示します", "https://wakayama-ramendb.supleks.jp"],
    "大阪,ラーメン": ["大阪府のラーメン屋さんを表示します", "https://osaka-ramendb.supleks.jp"],
    "京都,ラーメン": ["京都府のラーメン屋さんを表示します", "https://kyoto-ramendb.supleks.jp"],
    "奈良,ラーメン": ["奈良県のラーメン屋さんを表示します", "https://nara-ramendb.supleks.jp"],
    "兵庫,ラーメン": ["兵庫県のラーメン屋さんを表示します", "https://hyogo-ramendb.supleks.jp"],
		"滋賀,ラーメン": ["滋賀県のラーメン屋さんを表示します","https://shiga-ramendb.supleks.jp"]
};

const URL = "https://jlp.yahooapis.jp/NLUService/V1/analyze?appid="; // APIのリクエストURL
const APIID = "dj00aiZpPXJTc1ZxYllTaXV6RSZzPWNvbnN1bWVyc2VjcmV0Jng9ODU-"; // あなたのアプリケーションID

const startButton = document.querySelector('#startButton'); // 開始ボタン
const stopButton = document.querySelector('#stopButton'); // 停止ボタン
const resultOutput = document.querySelector('#resultOutput'); // 結果出力エリア

if (!'SpeechSynthesisUtterance' in window) {
		alert("あなたのブラウザはSpeech Synthesis APIに未対応です。");
}
const tts = new SpeechSynthesisUtterance(); // TTSインスタンスを生成
tts.lang = "ja-JP"; // 言語(日本語)、英語の場合はen-US
tts.rate = 1.0; // 速度
tts.pitch = 1.0; // 声の高さ
tts.volume = 1.0; // 音量

SpeechRecognition = webkitSpeechRecognition || SpeechRecognition;
if (!'SpeechRecognition' in window) {
		alert("あなたのブラウザはSpeech Recognition APIに未対応です。");
}

const asr = new SpeechRecognition(); // ASRインスタンスを生成
asr.lang = "ja-JP"; // 言語（日本語）
asr.interimResults = true; // 途中結果出力をオン
asr.continuous = true; // 継続入力をオン

let output = ''; // 出力

// 認識結果が出力されたときのイベントハンドラ
asr.onresult = function(event){
		let transcript = event.results[event.resultIndex][0].transcript; // 結果文字列

		let output_not_final = '';
		let res_counter = 0; //入力に対して答えたかどうかを判別するカウンタ
		if (event.results[event.resultIndex].isFinal) { // 結果が確定（Final）のとき
			asr.abort(); // 音声認識を停止

			let answer;
			let webpage;


			let keys = Object.keys(response);
			keys.forEach(function(key) {
					let flag = true;
					console.log(transcript);
					key.split(',').forEach(function(word) {
							let pattern = new RegExp(word);
							let flag_test = pattern.test(transcript); // マッチしたらtrue, しなかったらfalse
							flag = flag && flag_test; // 両方trueならtrue
					});

					if(flag){
							answer = response[key];
							console.log(key + " : " + answer);
							res_counter = 1;
					}
			});

			let keys_w = Object.keys(ramen);
			keys_w.forEach(function(key_w) {
					let flag_w = true;
					console.log(transcript);
					key_w.split(',').forEach(function(word) {
							let pattern = new RegExp(word);
							let flag_w_test = pattern.test(transcript); // マッチしたらtrue, しなかったらfalse
							flag_w = flag_w && flag_w_test; // 両方trueならtrue
					});

					if(flag_w){
						answer = ramen[key_w][0];
						webpage = ramen[key_w][1];
							console.log(key_w + " : " + answer);
							res_counter = 1;
					}
			});

			if (res_counter == 0){
					answer = "私の力不足で聞き取れませんでした" //undefindのかわりに文章を読み上げるようにしました。
					/*let queryURL = URL + APIID + "&intext=" + transcript;
					console.log(queryURL);

					// HTTPリクエストの準備
					const request = new XMLHttpRequest();
					request.open('GET', queryURL, true);
					request.responseType = 'json'; // レスポンスはJSON形式に変換

					// HTTPの状態が変化したときのイベントハンドラ
					request.onreadystatechange = function() {
							if (this.readyState == 4 && this.status == 200) {
							// readyState == 4 操作完了
							// status == 200 リクエスト成功（HTTPレスポンス）

							let res = this.response; // 結果はJSON形式

							Object.keys(res.result).forEach(function (key) {
								console.log(key + ": " + res.result[key])
							});
							// method が SAY のときのみ
							if(res.result.method == "SAY"){
								answer = res.result.param_text_tts || res.result.param_text;
								tts.text = answer;
							}
						}
					}*/

			}

			output += transcript + " => " + answer + '<br>';

			tts.text = answer;

			// 再生が終了（end）ときのイベントハンドラ（終了したときに実行される）
	    tts.onend = function(event){
            if(typeof webpage != 'undefined'){
								window.open(webpage);
            }
	    }

			speechSynthesis.speak(tts); // 再生
			// HTTPリクエストの実行
			//request.send();

		} else { // 結果がまだ未確定のとき
				output_not_final = '<span style="color:#ddd;">' + transcript + '</span>';
		}
		resultOutput.innerHTML = output + output_not_final;
}

// 開始ボタンのイベントハンドラ
startButton.addEventListener('click', function() {
		asr.start();
})

// 停止ボタンのイベントハンドラ
stopButton.addEventListener('click', function() {
		asr.stop();
		asr.abort();
})

</script>

</body>
</html>
